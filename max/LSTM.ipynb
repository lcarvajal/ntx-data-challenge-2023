{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZFLe8vOw6Ts",
        "outputId": "0d762189-2619-49df-a3df-840ad87d1590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aVdkHEm_w6T3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import dirname, join as pjoin\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib.pyplot import plot,figure\n",
        "from typing import List\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSignal(signal_fname:str, labels_fname:str, labels_to_use:List[str]):\n",
        "  raw_mat_fname = f'{signal_fname}_raw.mat'\n",
        "  filt_mat_fname = f'{signal_fname}_filt.mat'\n",
        "\n",
        "  raw_mat_contents = sio.loadmat(raw_mat_fname)\n",
        "  filt_mat_contents = sio.loadmat(filt_mat_fname)\n",
        "\n",
        "  raw_EEG = raw_mat_contents['EEG']\n",
        "  filt_EEG = filt_mat_contents['EEG']\n",
        "\n",
        "  fs = raw_EEG['srate'].item()[0].item()\n",
        "\n",
        "  raw_data = raw_EEG['data'].item()[0]\n",
        "  filt_data_1_to_35Hz = filt_EEG['data'].item()[0]\n",
        "  filt_data_4_to_18Hz = filt_EEG['data'].item()[1]\n",
        "\n",
        "  time = raw_EEG['times'].item()[0]\n",
        "\n",
        "  #Load marker data for S002 into dataframe\n",
        "  labels_fname = f'{labels_fname}_labeled.csv'\n",
        "  markers_df = pd.read_csv(labels_fname)\n",
        "\n",
        "  timestamp_labels = np.zeros((len(raw_data)))\n",
        "  for i,curr_label in enumerate(labels_to_use):\n",
        "    idx = markers_df.loc[markers_df[curr_label]>0,['Timestamp']].values\n",
        "    timestamp_labels[idx] = i+1\n",
        "\n",
        "\n",
        "  return raw_data, filt_data_1_to_35Hz, filt_data_4_to_18Hz, time, timestamp_labels"
      ],
      "metadata": {
        "id": "LzX8jNun6iaW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "tyHb4YOLw6UA"
      },
      "outputs": [],
      "source": [
        "class DatasetEEG(Dataset):\n",
        "    def __init__(self,signal:np.ndarray,labels: np.ndarray, transform, dev, window_len:int=7500):\n",
        "        super().__init__()\n",
        "        self.signal = signal\n",
        "        self.dev = dev\n",
        "        self.labels = labels\n",
        "        self.signal_len = signal.shape[0]\n",
        "        self.window_len = window_len\n",
        "        self.num_epochs = int(np.ceil(self.signal_len/self.window_len))\n",
        "        self.transform = transform\n",
        "\n",
        "        #split signal into epochs of length window_len\n",
        "        self.epochs = [self.signal[i*self.window_len:(i*self.window_len+self.window_len), :] for i in range(0,self.num_epochs-1)]\n",
        "        last_epoch = self.signal[(self.num_epochs-1)*self.window_len:, :]\n",
        "\n",
        "        #Add zero padding to final epoch and append to epochs list\n",
        "        if len(last_epoch) < window_len:\n",
        "          zeros = np.zeros((window_len - len(last_epoch),3))\n",
        "          last_epoch = np.append(last_epoch,zeros, axis = 0)\n",
        "        self.epochs.append(last_epoch)\n",
        "\n",
        "        self.epoch_labels = [self.labels[i*self.window_len:(i*self.window_len+self.window_len)] for i in range(0,self.num_epochs-1)]\n",
        "        last_epoch_labels = self.labels[(self.num_epochs-1)*self.window_len:]\n",
        "        #Add zero padding to final epoch and append to epochs list\n",
        "\n",
        "        if len(last_epoch_labels) < window_len:\n",
        "          zeros = np.zeros((window_len - len(last_epoch_labels)))\n",
        "          last_epoch_labels = np.append(last_epoch_labels,zeros, axis = 0)\n",
        "        self.epoch_labels.append(last_epoch_labels)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_epochs\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #if self.transform:\n",
        "        #    return self.transform(torch.tensor(self.epochs[index])), torch.tensor(self.epoch_labels[index])\n",
        "        return torch.tensor(self.epochs[index], device=self.dev, dtype=torch.float32), torch.tensor(self.epoch_labels[index], dtype=torch.long, device=self.dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "yZvFpKShw6UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf41ec9-b3b7-4bca-dbed-eea417cb0dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print(\"Using GPU\")\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print(\"Using CPU\")\n",
        "\n",
        "window_len = 7500\n",
        "labels_to_use = [\"SS1\",\"REM1\",\"REM0\",\"K1\"]\n",
        "\n",
        "\n",
        "#Get S002 and S003 data\n",
        "(S002_raw_data,\n",
        " S002_filt_data_1_to_35Hz,\n",
        " S002_filt_data_4_to_18Hz,\n",
        " S002_time, S002_markers) = getSignal('train_S002_night1_hackathon','train_S002', labels_to_use)\n",
        "\n",
        "(S003_raw_data,\n",
        " S003_filt_data_1_to_35Hz,\n",
        " S003_filt_data_4_to_18Hz,\n",
        " S003_time,\n",
        " S003_markers) = getSignal('train_S003_night5_hackathon','train_S003', labels_to_use)\n",
        "\n",
        "\n",
        "\n",
        "S002_signal_len = len(S002_filt_data_1_to_35Hz)\n",
        "S002_final_ind = S002_signal_len\n",
        "S002_signal = np.vstack((S002_raw_data,S002_filt_data_4_to_18Hz,S002_filt_data_1_to_35Hz))\n",
        "S002_signal = np.transpose(S002_signal,(1,0))\n",
        "\n",
        "\n",
        "#train_test_split(S002_signal)\n",
        "\n",
        "S002_data = DatasetEEG(\n",
        "                 signal=S002_signal,\n",
        "                 labels=S002_markers,\n",
        "                 transform = None,\n",
        "                 dev = device,\n",
        "                 window_len=window_len\n",
        "                 )\n",
        "\n",
        "train_dataloader = DataLoader(S002_data, batch_size=68, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(S002_signal, S002_markers, test_size=0.25)\n",
        "print(len(X_test) % 7500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq1LWNimJ5bz",
        "outputId": "33342370-eae6-4880-bb3f-1fcd5cf4cec7"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkkhQtYNw6UC"
      },
      "source": [
        "To Do:\n",
        "-Figure out issue with using full signal length (right now uncommenting \"[:len(filt_data_1_to_35Hz)-399],\" and removing last 399 samples)\n",
        "-Figure out need for final MLP layer after LSTM\n",
        "-Create training loop\n",
        "    -Add optimizer\n",
        "    -Add loss function\n",
        "    -Add backprop\n",
        "-Create metrics for performance assessment (WandB?)\n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "k0h1Y3NLw6UJ"
      },
      "outputs": [],
      "source": [
        "class LSTM1(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, dev):\n",
        "        super(LSTM1, self).__init__()\n",
        "        self.num_classes = num_classes #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "        self.seq_length = seq_length #sequence length\n",
        "        self.dev = dev\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True,device=self.dev) #lstm\n",
        "        self.fc_1 =  nn.Linear(hidden_size, 128, device=self.dev) #fully connected 1\n",
        "        self.fc = nn.Linear(128, num_classes,device=self.dev) #fully connected last layer\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=self.dev) #hidden state\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=self.dev) #internal state\n",
        "        # Propagate input through LSTM\n",
        "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "        out = self.relu(output)\n",
        "        out = self.fc_1(out) #first Dense\n",
        "        out = self.relu(out) #relu\n",
        "        out = self.fc(out) #Final Output\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N0WyGAhw6UL",
        "outputId": "3078fbd8-568e-4c03-b868-046370b2dab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.60797 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 11 #1000 epochs\n",
        "learning_rate = 0.001 #0.001 lr\n",
        "\n",
        "input_size = 3 #number of features\n",
        "hidden_size = 2 #number of features in hidden state\n",
        "num_layers = 1 #number of stacked lstm layers\n",
        "num_classes = len(labels_to_use) + 1 #number of output classes\n",
        "\n",
        "\n",
        "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, window_len, device)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()   # BCELoss for regression\n",
        "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #print(\"Epoch: \",epoch,\"\\n\")\n",
        "  for step,(x,y) in enumerate(train_dataloader):\n",
        "    #print(\"Batch: \",step)\n",
        "    #x = x.unsqueeze(dim=2)\n",
        "\n",
        "    outputs = lstm1.forward(x) #forward pass\n",
        "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
        "    y = torch.nn.functional.one_hot(y,num_classes).float()\n",
        "\n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    loss.backward() #calculates the loss of the loss function\n",
        "\n",
        "    optimizer.step() #improve from loss, i.e backprop\n",
        "  if epoch % 100 == 0:\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()),\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}